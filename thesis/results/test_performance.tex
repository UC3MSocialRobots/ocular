\section{Computing performance evaluation}
This section presents the results of the computing performance experiment. 
First, in section \ref{results_nodes}, the CPU and RAM usage of each of the nodes of the system is presented. 
Afterwards, in section \ref{results_topics}, the bandwidth and the publishing rate of each of the nodes is shown. 
	% \begin{itemize}
		% \item{\textbf{Package and nodes benchmarking}}
		\subsection{Nodes' CPU and RAM usage}
		\label{results_nodes}
		\\

			As it was explained in chapter \ref{methods}, the CPU and RAM usage is measured in the different nodes that compose the software. 
			There is a high difference in the CPU and RAM usage between nodes.
			The nodes that only perform a transformation of the data such as the converter node have a lower CPU and RAM consumption.
			The nodes that process the input images and point clouds have much higher values. 
			Figure \ref{node} shows the results of the experiment. 
\\

			The nodes with a higher computing consumption are the ROI segmenters and the feature extractors both 2D and 3D. 
			Since the 3D data has a higher size, the both the CPU and RAM usage of the nodes using 3D information is much higher than those processing 2D data. 
			The learner recognizer node also has a higher consumption than the converter, event handler or system output nodes. 
			This is because these perform simple conversions and computations of integers and floating data. 
			On the other hand, the learner recognizer node implements the state machine of the software. 
			This means it has to deal with a higher amount of data than the previous nodes. 
	\\

			The total CPU usage is lower than the 23\%, and the RAM usage of the whole software is of less than the 5\%. 
			Since the processing unit has 4 physical cores with two threads per core, the system needs less than one core to operate in real time. %the CPU consumption is of less than one physical core. 
			The computer used has 8 GB of RAM. 
			Using that number, the total RAM usage of the system is of 0.4 GB. 
			Figure \ref{node} shows that the CPU and RAM consumption of the third-party packages is very high. 
			The total CPU and RAM usage including the third-party packages is almost the double of the total of the OCULAR nodes. 
			This means that it is needed a computer featuring less than two cores (at 2.4 GHz) and less than 1 GB of RAM to be able to run the whole system on real time. 

\newpage 

\begin{table}[H]
\centering
\begin{tabular} {l c r@{.}l c r@{.}l }%c r@{.}l }
\toprule
\addlinespace[3mm]
   \multicolumn{1}{c}{\begin{center}\textbf{NODES}\end{center}} &
   % \multicolumn{3}{c}{\begin{center}\textbf{CPU USAGE(0 - 800)}\end{center}} &
   \multicolumn{3}{c}{\begin{center}\textbf{CPU USAGE(\%)}\end{center}} &
   \multicolumn{3}{c}{\begin{center}\textbf{RAM USAGE(\%)}\end{center}} &\\
\addlinespace[-3mm]
\midrule
Converter && %1&60 && 
0&20 && 0&50 \\
ROI segmenter 2D && %6&70 && 
0&84 && 0&50\\
ROI segmenter 3D && %106&70 &&
 13&34 && 1&50\\
Feature extractor 2D && %19&50 && 
2&44 && 0&10\\
Feature extractor 3D && %37&90 &&
 4&74 && 0&50\\
Event handler && %1&30 && 
0&16 && 0&50 \\
Learner recognizer &&% 8&30 && 
1&04 && 0&80 \\
System output && %1&00 && 
0&13 && 0&30 \\
\midrule
\textbf{TOTAL OCULAR NODES: } && %\textbf{183}&\textbf{00} &&
\textbf{22}&\textbf{88} && \textbf{4}&\textbf{70} \\
\midrule
pi\_tracker node: skeleton\_tracker && 4&86 && 3&2\\
openni\_launch nodelet && 16&19 && 1&00\\
\midrule
\textbf{TOTAL WITH THIRD-PARTY PACKAGES:} && %\textbf{183}&\textbf{00} &&
\textbf{43}&\textbf{84} && \textbf{8}&\textbf{90} \\
\bottomrule
\end{tabular}
\caption[Nodes' CPU and RAM usage]{Nodes' CPU and RAM usage}
\label{node}

\end{table}



			% \begin{figure}[h]
			% 	\begin{center}
			%     \includegraphics[width=\linewidth]{img/tests/node.png}
			% 	\caption[Nodes benchmarking]{Nodes benchmarking}
			% 	\label{node}
			% 	\end{center}
			% \end{figure}

		% \item{\textbf{Topic benchmarking}}\\
		\subsection{Topic network usage}
		\label{results_topics}

			The following figures \ref{hz} and \ref{bw} show the publishing rate and bandwidth of the different topics. 
			In figure \ref{hz}, the difference in the average rate between topics can be appreciated. 
			The publishing rate varies significantly between topics. 
			The first column shows the average number of messages published in each topic. 
			% It can be seen that those topics with lower-sized messages experiment a higher average publishing rate. 
			This is due to the reduced processing time and hence delay between message publishes. 
			All topics but one have a more or less similar average publishing rate.
			The bottle neck of the process that establishes the publishing rate is the kinect. 
			Since the information provided by this sensor is the input to most of the nodes of the system, their publishing rate is similar to the one of the kinect, 30 frames per second.  
			\\

			The only topic that publishes at a lower rate than the others is the final object ID topic. 
			This node transmits the output of the system, as was previously explained in section \ref{system_description}.
			The node that publishes it is buffering the object ID topic messages. 
			This creates a delay and the node publishes approximately one message per second in the final object ID topic. 
			% This knowledge matches the average rate observed of 0.75 messages per second. 
			% It is also confirmed when looking at the next column, in which the minimum time between messages is presented. 
			% All the previous topics have a zero or almost zero seconds. 
			% But final object ID observes a minimum time of around one second. 
				% This is reflected on the standard deviation column. 
			% The values for both object ID and final object ID, which are dependent on the system's event, are much higher than the rest of the topics. 

			\\


			Also it is noticeable the minimum rate column. 
			Most of the topics have a minimum publishing rate of 0 seconds.
			The only one that is different is the final object ID topic. 
			Another singular fact can be found in the maximum column. 
			All topics but two have less than 1 second as maximum publishing rate. 
			Those two are again final object ID and the object ID topic. 
			The reasons behind this particular behaviour are discussed in chapter \ref{discussion}. 
			\\

			The maximum column shows that the time between messages increases with the complexity of the processing performed by the node that publishes in that topic. 
			As an example, the segmented and descriptors topics have similar time, around half a second. 
			It is remarkable the value of the maximum time obtained by the object ID topic, which is the highest of the column. 
			% It was previously seen that this topic publishes the instant value of the estimated recognized object. 
			% The time between messages depend on the previous data transformation required. 
			% But also the event that the software is undergoing (learning or recognizing) affects that time. 
			The node that publishes in the object ID topic is the Learner-Recognizer node described in section \ref{learner_recognizer}.
			This node only publishes a message when the system is recognizing the objects. 
			If the system is learning new objects, there is no message published. 
			This could be the cause of the high result in the maximum time between messages column. 
			% When the system is learning, no estimations of the object ID are performed and hence no messages are published. 
			% On the other hand, when the system is recognizing, the topic is filled at a rate of almost thirty messages per second. 
			

			% \begin{figure}[h]
			% 	\begin{center}
			%     \includegraphics[width=\linewidth]{img/tests/topic_hz.png}
			% 	\caption[Topic benchmarking - Publishing rate]{Topic benchmarking - Publishing rate}
			% 	\label{hz}
			% 	\end{center}
			% \end{figure}

			\newpage

\begin{table}[H]
\centering
\begin{tabular} {l r@{.}l r@{.}l r@{.}l  r@{.}l  }
\toprule
\addlinespace[3mm]
   \multicolumn{1}{c}{\begin{center}\textbf{TOPIC}\end{center}} &
   \multicolumn{2}{c}{\begin{center}\textbf{\hspace*{-0.7cm}AVERAGE [Hz]}\end{center}} &
   \multicolumn{2}{c}{\begin{center}\textbf{MIN [s]}\end{center}} &
   \multicolumn{2}{c}{\begin{center}\textbf{MAX [s]}\end{center}} &
   \multicolumn{2}{c}{\begin{center}\textbf{STD DEV [s]}\end{center}} &\\

\addlinespace[-3mm]
\midrule
 Hand location & 27&56	&	0&00	&	0&04	&  \hspace*{0.5cm}	0&01 \\
 Segmented  image &  26&70	&	0&00	&	0&50	&	0&04\\
 Segmented  image  with  keypoints & 25&91	& 	0&00	&	0&50	&	0&03 \\
 Segmented  coordinates  (px) & 11&56 	&	0&05	&	0&13	&	0&03\\
 Segmented  point  cloud & 18&18 	&	0&05	&	0&26	&	0&01\\
 Descriptors  2D & 25&98 	&	0&00	&	0&50	&	0&03\\
 Descriptors  3D & 15&29 	&	0&00	&	0&42	&	0&05\\
 Event & 27&72  	&		0&00	&	0&04	&	0&01\\
 Object ID & 26&40 		&	0&00	&	4&23	&	0&21\\
 Final  object  ID & 0&75 	&	1&02	&	1&63	&	0&19\\
\bottomrule
\end{tabular}
\caption[Topic network usage - Publishing rate]{Topic network usage - Publishing rate}
\label{hz}
\end{table}



			% Table \ref{bw} shows the bandwidth consumed. 
			% It can be seen a huge difference between topics. 
			% The data ranges from the bytes to megabytes. 
			% The nodes using a bandwidth of bytes are segmented coordinates and final object ID. 
			% They are closely followed by the hand location, descriptors 2D, event and object ID topics that are in the kilobytes range. 
			% Finally, the ones using a higher bandwidth are the segmented image with and without keypoints, the segmented point cloud and the descriptors 3D topics. 
			% % \begin{figure}[h]
			% 	\begin{center}
			%     \includegraphics[width=\linewidth]{img/tests/topic_bw.png}
			% 	\caption[Topic benchmarking - Bandwidth]{Topic benchmarking - Bandwidth}
			% 	\label{bw}
			% 	\end{center}
			% \end{figure}






\begin{table}[H]
\centering
\begin{tabular} {l  c c c  }
\toprule
\addlinespace[3mm]
   \multicolumn{1}{c}{\begin{center}\textbf{TOPIC}\end{center}} &
   \multicolumn{1}{c}{\begin{flushright}\textbf{AVERAGE [kB/s]}\end{flushright}} &
   \multicolumn{1}{c}{\begin{flushright}\textbf{MIN [kB]}\end{flushright}} &
   \multicolumn{1}{c}{\begin{flushright}\textbf{MAX [kB]}\end{flushright}} &\\

\addlinespace[-3mm]
\midrule

Hand location & 1.38 &  0.12 	& 0.12  \\
Segmented image & 1.79$\cdot10^{3}$		&	60	&	60
\\
Segmented image with keypoints & $1.64$	&	60	&	60
\\
Segmented coordinates (px) & 212& 57 & 58 \\
Segmented point cloud & $1.48\cdot10^{3}$ & 	0	&	830
\\
Descriptors 2D & 29.48	&	0.81 &	1.26 
\\
Descriptors 3D & $2.60\cdot10^{3}$	&	140	&	170
\\
Event & 1.06&	0.05 &	0.06 
\\
Object ID & 1.39	&		0.03 & 		0.03 
\\
Final object ID & 1.15$\cdot10^{3}$	&		2$\cdot10^{3}$	&	2$\cdot10^{3}$	
\\
\midrule

\textbf{TOTAL: } & \textbf{6.65}$\mathbf{\cdot 10^{3}}$ && \\
\bottomrule

\end{tabular}
\caption[Topic network usage - Bandwidth]{Topic network usage - Bandwidth}
\label{bw}

\end{table}


% The  bandwidth results presented in figure \ref{bw} show the different sizes the data used have. 
			Figure \ref{bw} show the bandwidth measured in each of the system's topics. 
			There is a huge different in the results for the different topics, the numbers range from the bytes to the megabytes. 
			Those topics using custom messages use a higher bandwidth than those using a standard message such as a number. 
			\\

			This fact can be illustrated with the final object ID topic, which publishes integer messages and uses an average bandwidth of approximately 1 B/s. 
			The segmented coordinates in pixels topic is the one that has the next lowest bandwidth and its messages are vectors that contain two integers. 
			Its average bandwidth is around 200B/s. 
			\\

			In the kilobytes range, the hand location, descriptors 2D, event and object ID are located. 
			All but descriptors 2D are filled with custom made messages. 
			The data consists in integers and floats mixed with strings. 
			% For more information about custom messages, please read the chapter \ref{system_description}.
			It might be noted that the descriptors 2D topic is an order of magnitude higher than the other ones. 
			This is due to the fact that its messages are images and hence have a higher size than the other ones. 
			\\

			Finally, the megabytes range houses the segmented image topics as well as the segmented point cloud and the descriptors 3D. 
			All are filled with heavy messages that store two-dimensional and three-dimensional data.

	\end{itemize}