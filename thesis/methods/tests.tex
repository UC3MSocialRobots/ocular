\section{Code testing}
The code has been designed to be easily tested. The communication and ROS functions are separated from the actual computing of the nodes. 
\\

The class structure of the code is hence as follows: the base class performs the operations needed by the node and there exists a wrapper class that implements the publishing and subscribing to the different nodes. \\

In the actual application, it is an object of this latter wrapper class the one that is created. 
\\

This structure easies the testing, since the first testing level is done in the base classes and the second and third on the wrapper classes.
\\

For further details about the tools used to perform the testing please read the section \ref{testing}.
\\

In the following sections the libraries being tested in each level are presented. 

	\subsection{First level: Library unit test}
		The library used to perform this unit testing is gtest. More information about that library may be found in the section \ref{gtest}.
		In this level, the base classes are tested. Those classes are located in the src/libraries/libraries directory. The tests performed are: 
			\subsubsection{Converter Test}

			\subsubsection{ROI Segmenter 2D Test}

			\subsubsection{ROI Segmenter 3D Test}

			\subsubsection{Feature Extractor 2D Test}

			\subsubsection{Feature Extractor 3D Test}

			\subsubsection{Algorithm2D Test}

			\subsubsection{Algorithm3D Test}

			\subsubsection{Event Handler Test}

			\subsubsection{Data Parser Test}

	\subsection{Second level: ROS node unit test}
		In order to perform this testing level a library unit test and the rostest tool are needed.The rostest tool is explained in detail in the following \ref{rostest} section.\\

		The tests developed in this level are the following: 

	\subsection{Third level: ROS node integration / regression test}
		In order to perform a third-level testing, both a unit testing library and the rostest tool are needed. In this project, the tests implemented of this level are the following: 


\chapter{Performance testing}
The performance testing is used to benchmark the software developed. The different tests are explained below, ordered by the component of the software that is tested. 


\subsection{Package Benchmarking}
The whole package is benchmarked in order to obtain the CPU and RAM usages. This two parameters determine which systems would be able to handle the software and the specifications of the hardware needed to run the code under the desired time limits. 

\subsection{Node Benchmarking}
The ROS package is modular, the processing is distributed over different nodes. Each part of the processing sequence followed has different CPU and RAM usages, so the particular behavior of each node is studied. 
\\

There is a high difference between nodes. Those nodes that only perform a transformation of the data such as the converter node has a lower CPU and RAM consumption than the nodes that process the input images and point clouds. 

\subsection{Topic Benchmarking}
The topics communicate the nodes and allows the exchange of information. They are implemented in the ROS framework, which provides specific tools to measure their performance.
The parameters that are benchmarked are the bandwidth of the topics and their publishing rate.\\

The bandwidth parameter in a ROS topic is the maximum amount of data received over time, that is the maximum speed at which the data is transmitted. If there are network connectivity problems or rostopic cannot keep up with the publisher, the reported bandwidth might be lower than the actual one. This last possibility is due to the fact that rostopic is implemented in Python and hence it has a lower throughput than the roscpp-based nodes. 



\section{Effectiveness testing}

	The effectiveness test is designed to obtain data related to the accuracy of the code. Since the code implements a learner and recognizer algorithm, this test presents how well it does its job. 
\\

	In the following section the conditions and parameters that affect the test are shown and explained. 

	\subsection{Environment \& testing conditions}
		The test is performed in a room without a blank background and with various objects at different depths. It is hence a crowded background. 
		\\

		The light source is located behind the RGB-D sensor, illuminating the user. The objects that conform the dataset are located next to the tester to facilitate the accessibility to them. 

	\subsection{Testing procedure}
		The testing is performed following a certain sequence. First, the tester shows the first two objects that are going to be learned to the software. Afterwards, the recognition mode is tested identifying and storing in a file the output of the matching for both 2D and 3D. 
		\\

		Then, another new object is learned and again the recognition is tested. This sequence is iterated until there are no new objects to be learned. 
		\\

		The reason why doing an incremental learning is to observe the differences in the effectiveness and the benchmarking of the code when the dataset changes. 
		\\

		The whole procedure is going to be repeated for different number of object views to compare the differences in the software execution when increasing and decreasing them. Theoretically, decreasing the number of views should worse the effectiveness of the recognition but better the performance of the code, since the processing needed is reduced.

	\subsection{Dataset}
		The dataset that is going to be used was selected to be everyday use objects. This is because the software is intended to be running in a social robot that needs to recognize the most used objects. Also, the other possible application of the software is as an aiding software for visually impaired persons. In this case it is a requirement the recognition of daily objects as well.  
		\\

		Selecting this type of objects permits to obtain more reliable effectiveness testing. One characteristic that usually appears in these objects is the featurelessness. This fact difficult the object recognition, since the most textured objects are the ones that usually generate more reliable descriptors. \\

		In the code, in order to better the recognition, different views of each object are obtained and compared when doing the matching. Also, the introduction of both 2D and 3D features diminish the possibilities of false positives and false negatives. 

	\subsection{Effectiveness measurement}

		The effectiveness is measured differently for the learning mode than for the recognizing mode. 
		\\

		The first mode do not have a possibility of failing in learning, since all the different classes are previously tested and an error on it could only come from a software error. Having this in mind, the effectiveness of this mode is to create the best descriptors possible. 
		The best descriptor is that one that has a lower size but still is sufficiently robust to allow a good recognition performance. 
		\\

		In the case of the second mode, the recognizing, the effectiveness is measured in terms of false negatives and positives versus the true ones. The result is a percentage that indicates how well the features are matched. If the effectiveness is 0\%, the software has a 100\% of false positives and negatives, and if the effectiveness is a 100\%, there is a 100\% of true positives and negatives. \\

		