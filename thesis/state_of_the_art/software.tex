\newpage
\section{Object learning and recognition}

Object learning and recognition is an active field. 
In this section the most important works related to that field are presented. 
Also, the differences and improvements performed in this thesis with respect to the previous art are stated. 
% In this section the most important works related to this thesis are exposed. 

\subsection{Object learning and recognition using 2D and 3D input data}

This special branch in the object learning and recognition field has been active for many years. 
One of the first works in the field was the one performed by D.M.Gavrila and F.C.A. Groen. 
In 1992,  they developed a  system that performs 3D object recognition using 2D input data \cite{D.M.Gavrila1991}.
A 3D model was created and then the new 2D projection was matched to this model.
A geometric hashing method of matching was applied to the input 2D projection. 
The image was only matched to a model if the error to a nearby 2D projection was within certain thresholds.
The testing was performed under a controlled environment and using textured objects. 
The system would not give the same results in a real environment with noise and loosely defined objects. 
Also, the use of hashing limits the size of the dataset due to its high computing cost. 
\\

Later systems as \cite{Sheta2012} explore different descriptors for the objects that result less time-consuming. 
In this case, fuzzy logic is used to match the learned features to the new ones. 
Those descriptors are a set that include Affine \cite{Reiss:1991:RFT:117668.117680}, Zemike \cite{Teague} and Hu \cite{Hu1962} moments invariants among others. 
The results obtained a high percentage of true positives. 
But, again, the system uses a controlled setup:
The input is collected from three cameras that has a known illumination and orientation. 
The objects are white with significantly different shapes and they rest in a black background during learning and recognition phases. 
The applications in which it could be used are more related to the industrial field than the robotics field. 
\\

An outdoor system is described in \cite{Zia2013}, which demonstrated the effectiveness of two methods when combined: local descriptors and 3D wireframes. 
The system was able to distinguish between cars and bicycles and to estimate their pose. 
The input of the recognition is a single 2D image. 
Nevertheless, the training was made off-line, using a high number of Computer-Aided Design (CAD) model's views. 
\\

These systems differ with the one presented in this thesis in one major aspect: 
the user-software interaction. 
This thesis is based on providing an easy and intuitive interface. 
The learning process is performed easily and on-line and the recognition is real-time. 
There is no setting needed, no previous processing and care about the environment. 
The combination of 2D and 3D information in my system is, to the best of my knowledge, unique. 
The fact of recognizing the objects using those two different methods and then apply a decision algorithm better the results, reducing the effect of the noise.  



\subsection{In-hand object learning and recognition}

Most of the literature in object learning and recognition has been developed using wearable cameras as the input of the system. 
One of the most representative works is \cite{Roth2006}, which consists in a camera used to capture daily objects to construct a dataset more easily. 
Its main feature is that it eliminates the necessity of manually segmenting and labeling the learning datasets for object recognition libraries. 
It only learns new templates that are later fed to a off-line learning algorithm. 
\\

Another example is \cite{Philipose2009}, in which a benchmarking of an egocentric object recognition system is performed. 
This in-hand object recognition uses as input an image that has the object used at the center. 
The background is not segmented in this system because the errors produced by it may be neglected.
The object occupies most of the camera's frame and hence the processing of the input data to the system does not need to be as exhaustive as the one developed in this thesis.  
\\

The system presented here has a different approach: an in-hand object recognition and learning in which the user is located in front of the acquisition device. 
It is a solution to the same problem, the recognition of an object that a user holds, but the initial setting is different. 
In my thesis, the user is in front of the camera, because the software is running on a robot. 
The interaction between the software and the user is different from the previous art on the field. 
This change in the input creates an additional difficulty due to the hand's segmentation in the input image. 
\\

Furthermore, to the best of my knowledge there is no previous art in in-hand object learning and recognition using 2D and 3D information combined together. 
All of the algorithms described in this section use a camera and hence 2D data as input. 
The inclusion of 3D and the independence between the 2D and 3D recognition processes improve the noise resistance of my system with respect to the previous art. 


% \paragraph{Template matching}


% In the object recognition field obtaining good descriptors is of paramount importance. 
% The quality of the features extracted as the model of the object determine the quality of the algorithm. 
% Due to this importance, the next chapter is devoted to the descriptors that can be obtained from 2D and 3D data.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 				DESCRIPTORS 				%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55


\section{Feature Extraction algorithms}
In chapter \ref{fundamentals} a brief introduction to the characteristics of the different feature extractor algorithms was performed. 
In this section the different state-of-the-art algorithms for 2D and 3D feature extraction are presented and compared. 

\subsection{Algorithms for 2D Feature Extraction}
\label{2d_features}


The most used algorithms for general object recognition are presented in this section. 
% due to their relation between performance, invariantness and speed are exposed below. 
They appear in chronological order and the differences, similarities and improvements between them are explained. 
The selection of one algorithm or another depends on the application.


\paragraph{SIFT}\mbox{}\\
\label{sift}

SIFT (Scale Invariant Feature Transform) is a scale and rotation invariant feature descriptor \cite{sift}. 
There are various papers in which the performance of SIFT is compared with other descriptors and one of the most representative is \cite{Mikolajczyk2005}. In it, it can be seen that SIFT 
outperforms the previous algorithms, mainly due to its combination of local information and relative strengths and orientations of gradients. This combination makes it more robust to illumination and viewpoint changes and to noise. 
\\

The SIFT algorithm is based on four main phases: 
The first step is to detect the scale-space extrema, i.e. the location of potential interest points that are invariant to scale and rotation. 
The next step is to test those potential keypoints and select the more relevant based on measures of their stability. 
Then, one or more orientations are assigned to each of the previously obtained keypoints based on local image gradient directions. 
The following operations are performed on data that has been transformed relative to the location, scale and orientation of these features. 
This grants the invariantness to these transformations. 
The final phase consists on the description of the selected keypoint transforming the local image gradients into a representation that is descriptive enough to permit the information of various levels of shape distortion and illumination change. 
\\

In order to minimize the cost of extracting such a distinctive features, a cascade filtering approach is used in order to apply the most time-consuming operations only at locations that pass an initial test. 
It can be used for on-line applications but it still has a latency that was later improved. 
In order to reduce that lag, there were different approaches previous to the apparition of algorithms such as ORB, that reduced it drastically \cite{orb}. 
As an example, in \cite{sift_fpga} the SIFT algorithm was implemented on a FPGA (Field Programmable Gate Array), improving its speed by an order of magnitude and thus allowing it to run in real-time.
\\

The main reason of the high computing time of SIFT features is the descriptor vector size. 
In the aim of creating a highly distinctive descriptor, the vector is over-dimensioned slowing the detection, description and matching processes. 
This over-dimension is patent in the duplication of information that could be removed without affecting in a high degree its descriptiveness. 
% In relation with object recognition, this algorithm has a good performance in medium cluttered spaces. If the image is cluttered, there will appear a number of features of the background that do not have a match in the given database. Hence, it will give false positives and the match will have a lower probability. 




\paragraph{SURF}\mbox{}\\

SURF (Speeded Up Robust Features) is a scale and rotation invariant interest point or keypoint detector and descriptor \cite{surf}. 
It is a proprietary algorithm that simplifies the detection, extraction of the descriptors and matching steps thus obtaining them much faster than previous algorithms without losing repeatability, distinctiveness or robustness. 
\\

SURF algorithm is composed of three main steps: 
The first step of the algorithm is to identify the interest points such as corners, blobs or T-junctions, i.e. a junction were two lines meet forming a T. 
Therefore, this algorithm will be useful when evaluating a textured object.
The next step is to represent the neighbourhood of the interest points as a feature vector. 
The final step is to match the descriptor vectors between different images, in order to stablish a recognition of a pattern. Usually the matching is performed using as a reference the distance between the vectors. 
In this part, it can be perceived that the size of the descriptor vectors affects directly the performance of the algorithm. SURF aims to reduce that size without losing distinctiveness in the features. 
\\
\newpage
The SURF algorithm appeared after SIFT and hence it is interesting to see the similarities and differences between the two. 
In section \ref{descriptors} it was seen the good results obtained when combining the local information and relative data regarding gradients. This algorithm is based on similar characteristics: 
First, an orientation based on the information extracted from a circular region with the interest point as its center is obtained. Then, a square region aligned to that orientation is described and the descriptor is extracted from it.  
\\

The experiments in \cite{surf} show that the performance of these descriptors equals and in some cases improves the one of the SIFT descriptors. Also, the SURF descriptors are much faster computed and matched due to its smaller size. 


\paragraph{ORB}\mbox{}\\

ORB (Oriented FAST and Rotated BRIEF) is a fast rotation invariant, noise resistant binary descriptor based on BRIEF \cite{orb}.
ORB authors claim that it is two orders of magnitude faster than SIFT while matching its performance in many situations. 
Nevertheless, since ORB is not scale invariant, if the scale difference is noticeable the SURF algorithm will outperform ORB. 
\\

The features used in ORB build on the Features from Accelerated Segment Test (FAST) \cite{fast} keypoint detector and the Binary Robust Independent Elementary Features (BRIEF) \cite{brief} descriptor. Both of this previous algorithms offer a good performance and computing time relation. Since neither of them had the orientation taken into account, the main improvement made by the ORB developers is to include this feature in the algorithm. Also, the computation of oriented BRIEF features was improved and an analysis of variance and correlation for this features created. 
\\

FAST is mainly used to find keypoints in real-time systems that match visual features. The orientation operator included in this algorithm is the centroid operator described in \cite{orientation_corners}. This technique is not computationally demanding and also, unlike SIFT, it returns a single dominant result. 
\\

BRIEF uses simple binary tests whose performance is similar to SIFT with regard to robustness to lighting, blur and perspective distortion, but it is sensitive to in-plane rotation. In order to eliminate this drawback, the lowest computing costing solution is to steer BRIEF accordingly with the orientation of the keypoints. 
\\

In the different tests in \cite{orb} can be seen that the percentage of inliers obtained with ORB are higher and do not variate as much as those obtained by SIFT or SURF. 
ORB is then a good alternative for the latter if the application does not need a scale invariant descriptor. 
Finally, it is noticeable that this algorithm is Open Source.
Both SIFT and SURF are patent protected and the use for research is permitted, but for commercial uses the payment of a fee is needed. % is since the previous ones are proprietary. 
For all the above reasons, the ORB algorithm is the one being used in the system developed in this thesis. 


\subsection{Algorithms for 3D Feature Extraction}
\label{3d_features}


Applied to 3D data, a feature is a characteristic that describes a point inside the data. Features or descriptors can be compared to determine whether the point described is the same in two different inputs. They are used in object recognition and there are many different descriptors that can be used. Each of them has a certain speed in its computing and a reliability and robustness associated.
\\

Depending on the application in which they appear the developer must select the features depending on the specifications. 
As an example, two geometric point features are the underlying surface's estimated curvature and the normal at a specific query point. 
Both are local features and they characterize the point using the information provided by its neighbors. 
There are two types of features: local and global. 
Local features are less time-expensive but they are less robust. 
This means that two different objects may obtain very similar local features.
Global descriptors implement different techniques to generalize the information obtained for keypoints or important points in the mesh. 
They take more time to compute but are more robust than the previous ones. 
Since in our application the speed is key, local features are being used. 
\\

There exist a number of 3D local features that are computed using combinations of different geometric characteristics of the points. 
As an example, the 3D SIFT descriptor \cite{Scovanner2007} is obtained performing the 3D gradient and magnitude for each pixel, which is directly derived from its computation in 2D. 
It is rotation and scale invariant but is very time-consuming. 
The 3D descriptors being used in this thesis are the Point Feature Histogram (PFH) features. 

\subsubsection{Point Feature Histogram (PFH)}
\label{pfh}

The Point Feature Histogram \cite{Rusu2008} is a local 3D descriptor. 
It is fast to compute but its level of detail is limited. 
They are computed approximating the geometry of a point's k-neighborhood with a few values. 
This fact results in the possibility of obtaining a similar set of points in a very different object. 
\\

The PFH descriptors are invariant to rotation, position and point cloud density. 
They also perform well with noisy data. 
The features are created representing the mean curvature around the query point using a histogram of values. 
The normals' direction and magnitude of the points in the k-neighborhood of that point are studied. 
\\

The Fast Point Feature Histogram (FPFH) \cite{Rusu} descriptor is also a local descriptor based in the PFH. 
It is faster because it considers only the direct relations between the query point and its neighbors.
This fact makes them less robust than the previous descriptors. 
This is the reason why the Point Feature Histogram descriptors are the ones being used in this thesis instead of the Fast Point Feature Histogram descriptors. 
