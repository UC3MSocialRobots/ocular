%\addcontentsline{toc}{chapter}{Hardware}
\section{Hardware}



 
%%%%%%% INTRODUCTION %%%%%%
%%\addcontentsline{toc}{section}{Introduction}
%\section{Introduction}
The advance in the computer vision discipline is greatly linked with the development in the hardware. The main components of a computer vision system are the following: 

\begin{itemize}
	\item{Power Supply: } Device needed by the other components in order to work. 
	\item{Acquisition device: } Device that captures the world and represents it as an array of data. That data can be two or three dimensional. 
	\item{Processing unit:} Receives the information from the acquisition device and processes it. It is usually programmable. Nowadays the most used processing units are PCs. 
	\item{I/O unit: } Serves as a bridge between the acquisition device and the processing unit if needed. 

\end{itemize}

In this chapter the state of the art of the different acquisition devices is going to be presented. 

%%%%%% ACQUISITION DEVICES %%%%%%
%\addcontentsline{toc}{section}{Acquisition devices}
\subsection{Acquisition devices}
There are different acquisition devices being used in the computer vision field. They are usually classified depending on the output data they provide: 

\begin{itemize}
	\item{Cameras:}	The output data is two-dimensional. 
	\item{RGB-D sensors:} The output data is three-dimensional. 
\end{itemize}

The usage of one or another acquisition device depends on the application. The RGB-D sensors provide a higher number of information than the cameras. They reduce the ambiguities produced by the cameras when projecting the three-dimensional world into to dimensions. But also the RGB-D sensors output a higher amount of data. 
That is why, using three-dimensional information as the input of a software requires a higher-capacity processing unit than using two-dimensional data.



%%%%%% CAMERAS %%%%%%
%%\addcontentsline{toc}{section}{Cameras}
\subsection{Cameras}
\label{cameras}



%%%%%% RGB-D SENSORS %%%%%%
%\addcontentsline{toc}{section}{RGB-D Sensors or Natural Interaction Devices}
\subsection{RGB-D Sensors or Natural Interaction Devices}
\label{rgb-d}
%\addcontentsline{toc}{subsection}{History}
\subsubsection{History}

Computer vision is a field that needs specific hardware to retrieve a description of the world. This description has been done for a number of years in two dimensions. But this changed when the first version of an affordable RGB-D sensor appeared in 2010: the Kinect. This project uses a Kinect RGB-D sensor as the input of the system.
\\

This sensor was designed to be used in games, but developers soon realized the huge potential of the hardware for Computer Vision.  
Now, instead of a two-dimensional information as an input it was possible to have three-dimensional information. 
\\

The Microsoft corporation released the SDK (Software Development Kit) on June, 2011 \cite{kinectSDK}.
\\

But one year before, PrimeSense released their open source drivers and motion tracking middleware called NITE\cite{NITE}. 
PrimeSense is a company that manufactures RGB-D sensors and, in fact, the Kinect is based on their depth sensing reference. Hence, the software released by PrimeSense worked with the Kinect as well. 

From that time on, the OpenSource software related with the kinect has increased as well as the different models of RGB-D sensors available in the market.
In November 2010 OpenNI was created. Openni is an open-source software framework that can read the data from RGB-D sensors \cite{openni}.  

%\addcontentsline{toc}{subsection}{How does the Kinect work?}
\subsubsection{RGB-D sensors in this project}

