%\addcontentsline{toc}{chapter}{Hardware}
\section{Hardware}

The advance in the computer vision discipline is greatly linked with the development in the hardware. 
The hardware components present in a computer vision system are the following: 
% The main components of a computer vision system are the following: 

\begin{itemize}
	\item{Power Supply: } Device needed by the other components in order to work. 
	\item{Acquisition device: } Device that captures the world and represents it as an array of data. That data can be two or three dimensional. 
	\item{Processing unit:} Receives the information from the acquisition device and processes it. It is usually programmable. Nowadays the most used processing units are PCs. 
	\item{I/O unit: } Serves as a bridge between the acquisition device and the processing unit if needed. 

\end{itemize}

In this chapter the state of the art of the different acquisition devices is going to be presented. 

\subsection{Acquisition devices}
There are different acquisition devices being used in the computer vision field. 
They are usually classified depending on the output data they provide: 

\begin{itemize}
	\item{Cameras:}	The output data is two-dimensional. 
	\item{RGB-D sensors:} The output data is three-dimensional. 
\end{itemize}

The usage of one or another acquisition device depends on the application. 
The RGB-D sensors provide a higher number of information than the cameras. 
They reduce the ambiguities produced by the cameras when projecting the three-dimensional world into to dimensions. 
But also the RGB-D sensors output a higher amount of data. 
That is why, using three-dimensional information as the input of a software requires a higher-capacity processing unit than using two-dimensional data.



%%%%%% CAMERAS %%%%%%
%%\addcontentsline{toc}{section}{Cameras}
\subsection{Cameras}
\label{cameras}
There are many different types of cameras that are used in different applications. 
They might be classified according to the technology of the camera: 
\begin{itemize}
	\item\textbf{{CCD [Charged Coupled Device]:}}\\
	They have a high resolution but have a main drawback: the blooming. 
	The blooming is a saturation of the sensor when a high luminosity appears. 
	The sensor outputs a saturated zone bigger than the actual one, occluding part of the image. 
	\item\textbf{{CMOS [Complementary Metal Oxide Semiconductor]:}}\\
	This type of cameras have a semiconductor technology common to other devices such as memories or processors. 
	This fact makes them cheaper than the previous type. 
	Also, they have a smaller size and it is possible to access only a region of the image. 
	Finally, they do not suffer of blooming as the previous ones. 
\end{itemize}

Dimensions of the sensor: 
\begin{itemize}
	\item\textbf{{Linear:}}\\
	The output of this cameras is a vector of pixels in one dimension. 
	They are used mainly in industrial environments.
	Usually they are mounted in a linear actuator in order to cover a line along the region of interest. 
	They have a high resolution range. 
	\item\textbf{{Matricial:}}\\
	They output a matrix of pixels, two-dimensional. 
	They are used in all kinds of applications, from security to industrial ones. 
	The resolution in this type of cameras is more expensive than the previous type. 
	This means that for applications that need a high level of resolution usually linear cameras are preferred due to its cheapness. 
\end{itemize}


According to the number of sensors: 
\begin{itemize}
	\item\textbf{{1 sensor:}}\\
	This type of cameras usually output a black and white image. 
	Nevertheless, they might have colors if a filter such as the Bayer filter or the RGBW filter is used. 
	Those filters reduce the sensibility of the camera. 
	\item\textbf{{3 sensors: }}\\
	They are color cameras. 
	Usually there is a prism located inside the camera that reflects the image to each sensor. 
	Those sensors output the image in one of the RGB components. 
	Adding up them the final color image is obtained. 
\end{itemize}


The output type: 

\begin{itemize}
	\item\textbf{{Analog:}}\\
	Older cameras use this type of output. 
	Nowadays they are only used in certain applications such as security due to its cheapness. 
	They have higher level of noise than the next type of output. 
	\item\textbf{{Digital:}}\\
	This type of output is the most used currently. 

\end{itemize}

%%%%%% RGB-D SENSORS %%%%%%
\subsection{3D sensors}

Computer vision is a field that needs specific hardware to retrieve a description of the world. 
This description has been done for a number of years in two dimensions. 
3D sensors based on lasers devices existed for a long time but they are expensive. 
This fact diminished their use in the investigation field. 
But this changed when the first version of an affordable RGB-D sensor appeared in 2010: the Kinect. 
This project uses a Kinect RGB-D sensor as the input of the system.
\\

This sensor was designed to be used in games, but developers soon realized the huge potential of the hardware for Computer Vision.  
Now, instead of a two-dimensional information as an input it was possible to have three-dimensional information. 
In November 2010 OpenNI was created. Openni is an open-source software framework that can read the data from RGB-D sensors \cite{openni}.  
That same year, PrimeSense released their open source drivers and motion tracking middleware called NITE\cite{NITE}. 
PrimeSense is a company that manufactures RGB-D sensors and, in fact, the Kinect is based on their depth sensing reference. 
The software released by PrimeSense worked with the Kinect as well. 
From that time on, the OpenSource software related with the kinect has increased as well as the different models of RGB-D sensors available in the market.
The Microsoft corporation finally released the SDK (Software Development Kit) on June, 2011 \cite{kinectSDK}.



\paragraph{RGB-D Sensors or Natural Interaction Devices}\mbox{}\\

\label{rgb-d}

The 3D sensor consists on an infrared projector and an infrared camera. 
The projector creates an infrared pattern that is captured by the camera.
Then, it is compared with the references stored in the device and the depth of each point is estimated. 
Afterwards, the depth data is correlated to a RGB camera. 
The output can be described then as a point cloud, a type of data that consists on 3-dimensional and color information for each point.  
\\

It can be easily seen that the use of the infrared spectrum provides a system that can be easily perturbed. 
As an example, the incandescent light irradiates infrared waves that distorts the output of this type of RGB-D sensors. 
Also, the sun's IR waves affects the measures. 
The RGB-D sensors may be used hence only in interiors. 
