\chapter{The software}

%%%%% WHAT DOES IT DO? %%%%%%
%\addcontentsline{toc}{section}{What does the software do?}
\section{What does the software do?}
From the title of the thesis it can be inferred that the code has two differentiated parts: the learning mode and the recognizing mode. In either case, the input of the software is the image and the point cloud provided by the RGB-D sensor. 
But the output of the system varies depending on the mode we are working: 
\\
\begin{itemize}
	\item 	Learning mode:  the output is the percentage of learning completed. 
	\item   Recognizing mode: the output of the system is the identifier of the object, i.e. the number that represents which object in the dataset seems to be more similar to the one being shown to it currently. 
\end{itemize}

The recognizing mode is the default. It is used to match the new object the user has in his hand with those stored in the dataset. 
The learning mode is used to take different views of each object to be learned and create or increase the dataset. 


%%%%%% 	HOW CAN IT BE USED? %%%%%%
%\addcontentsline{toc}{section}{How can it be used?}
\section{How can it be used?}
This software has been thought to be used within a robot. This fact implies that there will not necessarily be a screen and a keyboard or some similar input and output devices to communicate with. In order to work and interact with the software, an easy and intuitive human-machine gestural interface was mandatory.  
\\

That interface has to contemplate four possible situations. Those depend on the hand being used (left or right, the code is able to work with either of them) and the location of that hand, which switches between the two modes present in the project: the recognizing and the learning mode. 

\begin{figure}
	\centering
    \includegraphics[width=0.45\textwidth]{img/intro/learning.eps}
	\caption[Learning Mode Triggering]{Learning mode triggering using the gestural interface}
\end{figure}


\begin{figure}
	\centering
    \includegraphics[width=0.45\textwidth]{img/intro/recognizing.eps}
	\caption[Recognizing Mode Triggering]{Recognizing mode triggering using the gestural interface}
\end{figure}

The software only allows one hand being used at a time. It is designed to select the highest hand. In order to obtain a correct result and avoid possible fluctuations of the program and the other packages being used, the user should keep the other hand close to the body. 
\\


In order to switch between the learning and recognizing modes of the program, the distance between the hand and the body
is being used: 
\\

If the hand is stretched out towards the RGB-D sensor, the software will start learning. If it is closer to the body, 
it will launch the recognizing mode, which is the default. 







%%%%%% GENERAL CHARACTERISTICS %%%%%%
\section{General characteristics}
This project is aimed to be part of a robotic system. In order for it to work properly on it, the processes should be as simple as possible to consume the lowest computing time possible. Those processes or nodes should as well run in parallel for the robot to work correctly. As an example, a robot that is using this software while walking along with the user must be able to perform that other tasks that allow it to walk while recognizing objects. Also, there are critical nodes that must be running continuously as the sensor data retrieving which is a crucial security element. 
\\

The structure of the software implemented is the one described above: the functionality is separated in nodes. Also, the code is modular in order to be able to reuse and modify it when developing complementary software such as hand gestures or object recognition upon a table for example. 
\\

Since the nodes of the program must communicate between them, a messaging system was needed. It could have been possible to implement one using pipes or shared memory, but the Robotic Operating System\cite{ros} is being used. More information about this useful tool might be found in the section. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%(!!!!SECTION).
\\

The code was structured to be as modular as possible. As it was explained before, one of the principal requirements was that it should be easily included in a robot. In order to easy that inclusion, the software developed in this thesis is built as a ROS package. 
The last release of that package might be downloaded from the following link. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%LINK


