\chapter{Introduction}
The robotic field has experimented an enormous increase in the past years. 

Different components and systems have improved.
As an example, cameras have evolved and low-cost 3D sensors have appeared. 
This fact provides a higher and more reliable amount of information for the computer vision system of the robot.  
Also, the processing units have been upgraded, allowing a higher amount of computing that permits the inclusion of more complex algorithms in these robots.  
% Different aspects of the robots has improved such as the sensors or actuators being integrated. 
% The processing and analysis of external data has been also upgraded. 
This leads to the increasing introduction of robots in human environments with assistive or social tasks. 
\\


The first automatisms performed their tasks without being aware of their environment. 
Their work area consisted mainly on closed areas in which humans were not allowed. 
But the introduction of robots in the houses and other places frequented by humans increases the importance of the environment perception. 
% The integration of robots in areas inhabited with humans increase the importance of the environment perception. 
The robot must be able to recognize and interact with the objects and persons around it. 
This interaction needs many different sensor or input systems and as many output systems to retrieve the information and respond to it.  
\\

% Humans are a key part in that interaction. 
% Social and assistive robots are designed to help humans in their everyday life. 
% To this purpose, the robot should be able to recognize gestures or poses of the users or actions they are performing in order to infer what they are feeling or what they need. 
% As an example, if the user has fallen, the robot should recognize the pose to deduce the user's status. 
% Afterwards, it might be able to conclude that the user needs help from him in order to get up. 
% Finally the robot might offer a support or even help the user in the standing up action. 
% \\

The human environment has a lot of variables that contain information about the user's intentions or actions. 
One of this variables are the objects the human uses. 
For example, if a person is holding a toothbrush, he is probably going to brush his teeth. 
Also, if the user is holding the keys in his hand he might be going out of the house. 
It can be easily seen that identifying the objects the humans hold in their hands, key information about the actions they are undergoing is extracted. 
If the robots could recognize those objects, they could adapt their behaviour to the situation arount them. 
As an example, if the user is holding a book, he is probably reading and  he does not want to be disturbed but for an emergency. 
The robot could then change its behaviour to the new constrains of the environment around it, for example, making as less noise as possible. 
\\

Having a system that could track and identify in-hand objects could improve the robot's interaction with its environment.
For this purpose I have developed a system that is able to learn and recognize hand-held objects in real time through a simple and intuitive gesture interface. 
This software is capable of recognizing the user's skeleton and from it extract the hands position. 
With this information the system studies the area around the hands and compares it with the previously acquired dataset.
It is possible to use the software without input and output devices such a screen or a mouse, since it integrates a pose interface. 
This fact easies the transition from the dataset acquisition to the recognition of objects and allows the system to be implemented in a robot. 



% Robots are being increasingly introduced in human envionments. 
% Social and assistive robot's behaviour depend on the actions of the individuals around it. 
% Some of those actions may be inferred fro the object the user is holding. 
% For exmple, if a human is holding his keys, he is likely to go out. 
% An assistive robot for visually impaired people may respond to this action by handing him over his cane. 
% Recognizing the object the user is holding may help the robot to understand better the situation, improving the human-robot interaction. 
% For this purpose I have developed a system that is able to learn and recognize hand-held objects in real time through a simple and intuitive gesture interface. 

% \newpage 
\input{intro/context}

% \newpage

\input{intro/motivation}

%\newpage

\input{intro/solution}

%\newpage

\input{intro/regulatory_compliance}

%\newpage

\input{intro/objectives}

%\newpage

\input{intro/thesis_structure}
