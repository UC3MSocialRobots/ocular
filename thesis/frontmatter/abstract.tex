\begin{abstract}

% \large{\textbf{OCULAR: In-hand object detection and tracking using 2D and 3D information}}
% \\

% Irene Sanz Nieto, July 11 2014.


\chapter{Abstract}

As robots are introduced increasingly in human-inhabited areas, they would need a perception system able to detect the actions the humans around it are performing in order to act accordingly in this changing environment.
One of the most useful informations that could be extracted to recognize the actions are the objects that the person is using, because humans utilize different objects and tools in various tasks. 
As an example, if a person is holding a book, he is probably reading. 
The information about the objects the humans are holding is useful to determine the activities they are undergoing.  
\\

This thesis presents a system that is able to track the user's hand and learn and recognize the object being held.
When instructed to learn, the software extracts key information about the object and stores it with a unique identification number for later recognition.
If the user triggers the recognition mode, the system compares the current object's information with the data previously stored and outputs the best match.
The system uses both 2D and 3D descriptors to improve the recognition stage.
In order to reduce the noise, there are two separate matching procedures for 2D and 3D that output a preliminary prediction at a rate of 30 predictions per second. 
% Afterwards, a final decision step is performed that eliminates the high-frequency noise and outputs the best prediction.
Finally, a weighted average is performed with these 30 predictions for both 2D and 3D and the final prediction of the system is obtained.
\\

The experiments carried out to validate the system reveal that it is capable of recognizing objects from a pool of 6 different objects with a F1 score value near 80\% for each case.  
The introduction of a weighted average improved the recognition performance of the system. 
The results demonstrated that the F1 score obtained in the system when using the average is better than the F1 score obtained by the individual 2D and 3D predictions.  
The performance tests show that the system is able to run on real time with minimum computer requirements of roughly one physical core (at 2.4GHz) and less than 1 GB of RAM memory. 
Also, it is possible to implement the software in a distributed system since the bandwidth measurements carried out disclose a maximum bandwidth lower than 7 MB/s. 
\\

% Las últimas frases deberían describir como cambia el contexto de tu campo de investigación tras tu tesis. Describe cual ha sido tu aportación y como afecta a la ciencia y a tu campo de investigación. Tienes que dejar muy claro por qué tus resultados son importantes: has aplicado una técnica de reconocimiento de objetos que nadie más había hecho en el campo de HRI, y has demostrado que es posible enseñar a robots objetos en mano en tiempo real. Esto podría permitir que usuarios sin conocimientos de programación puedan enseñar objetos cotidianos a robots. (enróllate un poco más)
This system is, to the best of my knowledge, the first in the art to implement an in-hand object learning and recognition algorithm using 2D and 3D information.
The introduction of both types of data and the inclusion of a posterior decision step improves the robustness and the accuracy of the system. 
The software developed in this thesis is to serve as a building block for further research on the topic in order to create a more natural human-robot interaction an understanding. 
This creation of a human-like interaction with the environment for robots is a crucial step towards their complete autonomy and acceptance in human areas. 

% The goal of the system is to serve as the base for further research on the topic to improve the interaction between humans and robots. 
% More specifically, it might be used for social or assistive robots as an input. 
% Evaluating the objects that the humans are holding may help to analyze the context around the robot. 
% This is a crucial step in the path to the complete autonomy of social and assistive robots. 

% This system could be integrated as part of the perception mechanism of social and assistive robots to improve its response to the changing conditions of its environment.
% Following the previous example, from the information extracted that the user is holding a book, the robot might be able to infer that the human does not want to be disturbed, except for an emergency. 
% From the example it may be extracted that this system could help to create a more natural human-robot interaction and understanding by providing information about the objects that are hand-held.


% % Part 1: What is the problem? What is the topic of this paper?

% This thesis presents a system that is able to learn and recognize objects that are being held by a human. 
% Robots are being introduced increasingly in human-inhabited areas and they need a perception system able to detect the actions the humans around it are performing in order to act accordingly in this changing environment.
% The information about the objects the humans are holding is useful to determine the activities they are undergoing.  
% % This information can be useful for the robot's interaction with its environment. 
% % In particular, the introduction of robots to assist humans could improve our quality of life. 
% % However, current robots have a limited perception of their environment, which impedes them to provide proper assistance. 
% % The goal of this thesis is to remedy this problem. 
% % In order to perform complicated tasks related to human aiding, the robot's perception systems should be improved. 
% % The robot should be able to recognize tasks being performed and adapt its behaviour accordingly.
% % For example, if one is reading, i.e. holding a book, one should not be disturbed unless necessary.
% % Having a system that identifies the objects being held can improve the robot's response. 
% \\

% % Part 2: How is the problem solved (methodology)?

% This thesis presents a system that is able to track the user's hand and, by means of a gestural interface, learn or recognize the object being held. 
% When instructed to learn, the software extracts key information about the object and stores it with a unique identification number for later recognition. 
% If the user triggers the recognition mode, the system compares the current object's information with the data previously stored and outputs the best match.


% \\
% % Part 3: What are the specific results? How well is the problem solved?

% % The experiments carried out to validate the system reveal that the software is able to differentiate between similar objects reliably and that the accuracy of the system increases linearly with the amount of data obtained.
% The experiments carried out to validate the system reveal a F1 score value augment with the increase of views per object being learned. 
% This is supported by the fact that the highest F1 score (more than 80\% for all the experimental objects) was obtained when using the maximum number of views per object of the experiments (10 views per object). 
% The computing performance evaluation revealed that the total bandwidth used is lower than 7 MB/s, which allows its implementation in a distributed system. 
% This evaluation showed as well that the minimum computer requirements for the system to run on real time are of roughly one physical core (at 2.4 GHz) and less than 1 GB of RAM memory. 

% % The learning and recognizing stages were optimized to allow the software to operate in real time, which is key to obtain a good interaction with the robot. 



% \\
% % Part 4: So what? How useful is this to science or to the reader?
% This system could be integrated as part of the perception mechanism of social and assistive robots to improve its response to the changing conditions of its environment. 
% It could help to create a more natural human-robot interaction and understanding by providing information about the robots that are hand-held. 

% % Therefore, having the capability to introduce common objects to the robot's knowledge can enhance its response to different scenarios. 
% % This upgrade in the decision making process may allow robots to assist humans more appropriately. 








% %%% COMMENTED OUT PARTS

% % This bachelor's thesis consists in a software that implements an in-hand object learning and recognition using 2D and 3D information. 
% % The code is Open-Source and it was designed to be running inside a robot. 
% % The idea is to create a new stand-alone module that could be included in different robots. 
% % This package would aid in the environment perception of the robot. 
% % \\

% % The thesis is structured as follows. 
% % First, the purpose and motivations are presented and a brief description of the project is performed. 
% % Afterwards, the state of the art is explained and the innovations performed in this thesis with respect to the previous art are highlighted. 
% % Then, the system developed is described as well as the experiments performed on it. 
% % Finally, the results are shown and discussed and the conclusions derived from them explained.
% % This project is aimed as a proof of concept study and hence the possible improvements observed from the experiments are also presented in the last section. 
% % \\

% % The analysis of the system demonstrated an increase of the accuracy with the increment of views per object acquired.
% % The results depicted the robustness of the system as well, since it is able to differentiate between similar objects a high number of times  
% % The first world's population is ageing. 
% % This fact is going to affect the economy of these countries since elder people need more care and are not able to work. 
% % The introduction of robots to assist in the care of elder people could help in this situation. 
% % 1)However, todays robots are limited in perception, and hence need an advanced recognition syste
% % 2)However, current robots have a limited environment perception. 
% % This fact handicaps them and thus an updated perception system could allow them to interact with its environment more efficiently. 
% % Nevertheless, nowadays most robots are able to interact with its environment in a limited way. 



% % The recognition of the tasks the human is performing could be useful to determine the%is important to understand the situations. 
% % The objects the person is holding gives a huge amount of information about the task being performed, i.e. if he is holding a book, he is probably going to read. 

% % Since it is intended to be running in a robot, the most natural way of interacting with it is through gestures. 
% % A gestural interface has been developed that allows to switch between the learning and recognizing modes. 
% %, when instructed through the pose interface, store information about the object being held. 
% % The software incorporates an easy and intuitive pose interface that allows to easily l. 

% % The software is able to easily learn new objects. 
% % It is possible to obtain a defined number of views per object to improve the later recognition. 
% % The system also incorporates an easy and intuitive pose interface to interact with it. 
% % The results of the experiments performed on the system can be seen in section \ref{results}. 
% % They show that the system improves its accuracy with the number of views per object. 
% % Also, the confusion matrices reveal a good robustness of the algorithm when using similar objects. 
% % The software is able to learn and recognize in real time, which is very useful to obtain a good interaction with the robot. 
% \\

% % The system is intended to be a piece in the situation recognition algorithm of the robot. 
% % It is able to effectively learn and recognize objects that are hand-held, giving information that can be key to determine the tasks the human is developing. 
% % It could be a piece of information useful to develop a better human-robot interaction for social and assistive robots. 
% % It may, in fact, be introduced in the robot that probably will take care of us when we are older. 
% % The experiments performed on the system reveal a good robustness when comparing similar objects and also a better performance when increasing the data stored in the learning phase. 


\end{abstract}


\chapter{Resumen}
\begin{abstract}

Los robots están siendo introducidos en areas habitadas por humanos cada vez en mayor medida. 
Este hecho que hace necesaria la inclusión de un sistema de percepción que sea capaz de detectar las acciones que las personas a su alrededor están realizando para poder actuar de acuerdo a este entorno cambiante. 
Una de las informaciones más útiles que se puede extraer para identificar las acciones que están haciendo los humanos son los objetos que éstos usan. 
Por ejemplo, si una persona está sosteniendo un libro probablemente esté leyendo. 
Esta información acerca de los objetos que las personas sostienen es útil para determinar lo que están haciendo. 
\\

Esta tesis presenta un sistema que es capaz de seguir la mano del usuario y aprender y reconoce el objeto que ésta sostiene. 
Durante el modo de aprendizaje, el programa extrae información importante sobre el objeto y la guarda con un número de identificación único. 
El modo de reconocimiento por su parte compara la información extraída del objeto actual con la guardada previamente y obtiene el que es más parecido. 
El sistema utiliza descriptores 2D y 3D para mejorar la fase de reconocimiento. 
Para reducir el ruido, se compara la información 2D y 3D por separado y se extrae una predicción preliminar a una velocidad de 30 predicciones por segundo. 
Posteriormente, se realiza una media ponderada de esas 30 predicciones y la predicción final del sistema es obtenida. 
\\

Los experimentos realizados para validar el sistema revelan que es capaz de reconocer objetos de un conjunto total de 6 con un F1 score cercano al 80\% en todos los casos. 
La introducción de la media ponderada mejora el reconocimiento realizado por el sistema. 
Los resultados demuestran que el F1 score obtenido por el sistema es mejor que aquel obtenido por las predicciones individuales en 2D y 3D. 
Los tests de rendimiento que se han realizado en el sistema demuestran que es capaz de operar en tiempo real. 
Para ello necesita un ordenador con unos requerimientos mínimos de un core (a 2.4 GHz) y menos de 1 GB de memoria RAM. 
También demostraron que es posible implementar el programa en un sistema distribuído debido a que el máximo de ancho de banda obtenido es menor de 7 MB/s. 
\\

El sistema es, según los datos de que dispongo, el primero en implementar un reconocimiento y aprendizaje de objetos en mano utilizando información 2D y 3D. 
La introducción de ambos tipos de datos y de una posterior etapa de decisión mejora la robustez y la precisión del sistema. 
El programa desarrollado en esta tesis sirve como un primer paso para incentivar la investigación en este campo, con la intención de crear una interacción más natural entre humanos y robots. 
La introducción en los robots de una interacción similar a la humana con el entorno es un paso crucial hacia su completa autonomía y aceptación en áreas habitadas por humanos. 






% El presente Trabajo de Fin de Grado presenta un sistema capaz de aprender objetos nuevos sostenidos por una persona y reconocer aquellos que han sido aprendidos previamente. 
% Esta información puede ser útil para mejorar la interacción del robot con su entorno. 
% En particular, la introducción de robots para ayudar a las personas podría mejorar nuestra calidad de vida. 
% Sin embargo, los robots actuales tienen una percepción del entorno limitada, lo cual impide que den una assistencia apropiada a los usuarios. 
% La meta de este Trabajo es remediar ese problema. 
% \\

% Para ser capaces de realizar tareas complicadas relacionadas con la asistencia a personas, los sistemas de percepción de los robots deben ser mejorados. 
% El robot debe ser capaz de reconocer tareas que están realizando las personas y adaptar su comportamiento a ellas. 
% Por ejemplo, si una persona está leyendo, esto es, sujetando un libro, el robot debería poder inferir que la persona no desea ser molestada si no es necesario. 
% El hecho de tener un sistema que identifique los objetos cogidos por los usuarios puede mejorar la respuesta del robot. 
% \\

% Este proyecto presenta un sistema capaz de seguir las manos del usuario y, a través de una interfaz gestual, aprender o reconocer el objeto que la persona está cogiendo. 
% Cuando el usuario activa el modo de aprender, el software extrae información del objeto y la guarda, relacionándola con un identificador único usado posteriormente en el reconocimiento. 
% Si el modo de reconocer es activado, el sistema compara la información del objeto actual con los datos guardados previamente y extrae como resultado el identificador del objeto más parecido. 
% Los experimentos que han sido realizados revelan que el programa es capaz de diferenciar entre objetos similares fiablemente y que la exactitud del sistema aumenta linearmente con la cantidad de información obtenida en el proceso de aprendizaje. 
% Los procesos de aprendizaje y reconocimiento han sido optimizados para permitir que el sistema opere en tiempo real, algo crucial para garantizar una buena interacción con el robot. 
% \\

% Por tanto, el hecho de tener la capacidad de incorporar objetos cotidianos al conocimiento del robot puede mejorar su respuesta a situaciones diferentes. 
% Esta mejora en el proceso de decisión podría permitir a los robots ser capaces de ayudar y asistir a las personas de una forma más apropiada. 

\end{abstract}